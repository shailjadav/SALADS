<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations"/>
  <meta property="og:url" content="https://shailjadav.github.io/SALADS/"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <title>Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/icon2.png">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://shailjadav.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>

<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations</h1>
          <div class="is-size-3 publication-authors">
            ICRA, 2024
          </div>
        </div>
    </div>
  </div>

</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="is-size-5 publication-authors">
           <span class="author-block"><a href="https://evm7.github.io/" target="_blank">Shail Jadav</a>,</span>
           <span class="author-block"><a href="https://www.tuwien.at/en/etit/ict/asl/team/johannes-heidersberger" target="_blank">Johannes Heidersberger</a>,</span>
           <span class="author-block"><a href="https://www.acin.tuwien.ac.at/staff/cott/" target="_blank">Christian Ott</a>,</span>
           <span class="author-block"><a href="https://www.tuwien.at/etit/ict/asl/team/dongheui-lee" target="_blank">Dongheui Lee</a>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Indian Institute of Technology Gandhinagar, Technische Universit Ìˆat Wien (TUWien), German Aerospace Center (DLR)</span> 
          </div>
          


          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              
              <!-- PDF Link. -->
<!--              <span class="link-block">-->
<!--                <a href="static/source/ADDHEREPDF.pdf" target="_blank"-->
<!--                  class="external-link button is-normal is-rounded">-->
<!--                  <span class="icon">-->
<!--                    <i class="fas fa-file-pdf"></i>-->
<!--                  </span>-->
<!--                  <span>Paper</span>-->
<!--                </a>-->
<!--              </span>-->
<!--                            </span>-->
              <!-- </span> -->
              <!-- Colab Link. -->
<!--              <span class="link-block">-->
<!--                <a href="ADD HERE THE CODE" target="_blank"-->
<!--                class="external-link button is-normal is-rounded">-->
<!--                <span class="icon">-->
<!--                  <i class="fab fa-github"></i>-->
<!--                </span>-->
<!--                <span>Code</span>-->
<!--              </a>-->
<!--             </span>-->

<!--              <span class="link-block">-->
<!--                <a href="ADD HERE REPLICATE IF NEEDED" target="_blank"-->
<!--                class="external-link button is-normal is-rounded">-->
<!--                <span class="icon">-->
<!--                  <i class="fas fa-rocket"></i>-->
<!--                </span>-->
<!--                <span>Demo</span>-->
<!--              </a>-->
<!--              </span>-->
              <!-- </span> -->
              <!-- Colab Link. -->
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-small">
  <!~~ <div class="hero-body"> ~~>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!~~ <div id="results-carousel" class="carousel results-carousel"> ~~>
      <div class="container">
      <div class="item">
      <div class="column is-centered has-text-centered">
        <img src="static/figures/teaser.png" alt="UNIMASKM"/>
      </div>

    </div>
  </div>
 <!~~  </div> ~~>
  </div>
  </div>
 <!~~  </div> ~~>
</section>
 -->

  <section class="hero is-small">
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="container">
        <div class="item">
          <p style="margin-bottom: 30px">
 
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/videos/overview.mp4"
          type="video/mp4">
        </video>
        </p>
        </div>
    </div>
  </div>
  </div>
  </div>
</section>
    
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This article introduces a framework for complex human-robot collaboration tasks, such as the co-manufacturing of furniture. For these tasks, it is essential to encode tasks from human demonstration and reproduce these skills in a compliant and safe manner. Therefore, two key components are addressed in this work: motion generation and shared autonomy. We propose a motion generator based on a time-invariant potential field, capable of encoding wrench profiles, complex and closed-loop trajectories, and additionally incorporates obstacle avoidance. Additionally, the paper addresses shared autonomy (SA) which enables synergetic collaboration between human operators and robots by dynamically allocating authority. Variable impedance control (VIC) and force control are employed, where impedance and wrench are adapted based on the human-robot autonomy factor derived from interaction forces. System passivity is ensured by an energy-tank based task passivation strategy. The framework's efficacy is validated through simulations and an experimental study employing a Franka Emika Research 3 robot.
           </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/overview.jpg" alt="Motivation of our model"/>
      </div>    
  </div>
</div>
</div>
</section>




<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
         <h2 class="title is-3">How does it work?</h2> 
        <div class="content has-text-justified">
          <p>
            Our framework leverages a sophisticated shared autonomy framework designed to enhance human-machine collaboration. At its core, it features a state-of-the-art motion generator capable of encoding task-specific movements and wrench profiles. This motion generator is adept at navigating complex, closed-loop paths while seamlessly incorporating obstacle avoidance, ensuring smooth and efficient operations across diverse environments.
          </p> <p>
          Building upon this foundation, our approach introduces a Variable Impedance and Force Control (VIC) system. This system is meticulously crafted to ensure precise trajectory following and force application, adjusting dynamically to different levels of human interaction and responding effectively to any human-induced changes. Such adaptability ensures that machines can work in perfect harmony with their human counterparts, enhancing productivity and safety.
        </p> <p>
        A key element of the system is the integration of an energy-tank-based passivation strategy. This strategy ensures the system remains stable and responsive even as it adjusts to changing control parameters and impedance levels, drawing on advanced concepts to maintain operational integrity.
      </p> <p>
        Proposed methodology has been rigorously tested through extensive experiments and simulations, demonstrating its effectiveness and reliability. This framework opens new avenues for human-machine collaboration, promising significant advancements in industrial, medical, and service applications.
        </p>
        <div class="columns is-centered has-text-centered">
            <div class="item">
          <p style="margin-bottom: 30px">
<!--
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/MDM-page.mp4"
          type="video/mp4">
        </video>
 --><br><br>
        </p>
        </div>
            </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

    
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/modeloverview.png" alt="Architecture of our ECHO model"/>
      </div>    
  </div>
</div>
</div>
</section>


      <section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparision with SEDS and LPV-DS</h2>
          <p>
            To evaluate the effectiveness of our method, we compared it with SEDS and LPV-DS by using the leaf shape from the LASA handwriting dataset, as shown in above figure. Although both SEDS and LPV-DS managed to reach the final point, they couldn't accurately copy the original example. LPV-DS had a smaller error in following the path than SEDS, but still couldn't match the original example closely.
          </p><p>
            In above figure, the red lines show the original examples, black lines with arrows represent the path of movement, and solid black lines are the attempts to recreate the examples. Our method uses the average path from the examples, marked with a green dashed line in above figure. It's worth noting that our method only needs one example, chosen from many based on the best performance. Our findings show that points starting away from the example path eventually meet and then follow this average path, reaching the end goal. This proves our method can capture complex shapes, including those that don't directly move closer to the target over time. Our technique also works well with other shapes in the LASA handwriting dataset.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 

 


    
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@article{jadav2024salads,
  title={Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations},
  author={Jadav, Shail and Heidersberger, Johannes and Ott, Christian and Lee,Dongheui},
  journal={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024}
}</code></pre>
    </div>
</section>




<footer class="footer">
 <!--  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
      href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
      <i class="fas fa-file-pdf"></i>
    </a>
    <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
      <i class="fab fa-github"></i>
    </a>
  </div> -->
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>

  </body>
  </html>
